{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_pytorch_svhn.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":["KCFxdqUmK0Ix"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"7W_lSrg5H6dq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":988},"outputId":"b0f6bda2-e2ab-4695-ea09-67706d50a28f","executionInfo":{"status":"error","timestamp":1526405269832,"user_tz":-120,"elapsed":8655,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/45/99/837428d26b47ebd6b66d6e1b180e98ec4a557767a93a81a02ea9d6242611/GPUtil-1.3.0.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.3)\n","Building wheels for collected packages: gputil\n","  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/17/0f/04/b79c006972335e35472c0b835ed52bfc0815258d409f560108\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.3.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.5)\n","Collecting humanize\n","  Downloading https://files.pythonhosted.org/packages/8c/e0/e512e4ac6d091fc990bbe13f9e0378f34cf6eecd1c6c268c9e598dcf5bb9/humanize-0.5.1.tar.gz\n","Building wheels for collected packages: humanize\n","  Running setup.py bdist_wheel for humanize ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/69/86/6c/f8b8593bc273ec4b0c653d3827f7482bb2001a2781a73b7f44\n","Successfully built humanize\n","Installing collected packages: humanize\n","Successfully installed humanize-0.5.1\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c2471adc86d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPUtil\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mGPUs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetGPUs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# XXX: only one GPU on Colab and isn’t guaranteed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/GPUtil/GPUtil.py\u001b[0m in \u001b[0;36mgetGPUs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetGPUs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Get ID, processing and memory utilization for all GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nvidia-smi\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"--query-gpu=index,uuid,utilization.gpu,memory.total,memory.used,memory.free,driver_version,name,gpu_serial,display_active,display_mode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--format=csv,noheader,nounits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# output = output[2:-1] # Remove b' and ' from string added by python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    707\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nvidia-smi': 'nvidia-smi'"]}]},{"metadata":{"id":"rCj7B-azv_0D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":499},"outputId":"bf93a2bf-3cca-4bd7-9b7d-150f7873ef2d","executionInfo":{"status":"ok","timestamp":1526405341731,"user_tz":-120,"elapsed":48548,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["!pip install imageio\n","!pip install torch torchvision"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting imageio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/1d/33c8686072148b3b0fcc12a2e0857dd8316b8ae20a0fa66c8d6a6d01c05c/imageio-2.3.0-py2.py3-none-any.whl (3.3MB)\n","\u001b[K    100% |████████████████████████████████| 3.3MB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.14.3)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.45.1)\n","Installing collected packages: imageio\n","Successfully installed imageio-2.3.0\n","Collecting torch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n","\u001b[K    28% |█████████▏                      | 138.7MB 35.6MB/s eta 0:00:10"],"name":"stdout"},{"output_type":"stream","text":["\u001b[K    100% |████████████████████████████████| 484.0MB 26kB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x5ca2a000 @  0x7f63dd5491c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n","\u001b[?25hCollecting torchvision\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 7.4MB/s \n","\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/4b/8b54ab9d37b93998c81b364557dff9f61972c0f650efa0ceaf470b392740/Pillow-5.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 15.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Installing collected packages: torch, pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.1.0 torch-0.4.0 torchvision-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"jpbEz3JktpaP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"5a01b5d7-5441-4f46-f772-649daffd8ece","executionInfo":{"status":"ok","timestamp":1526405356802,"user_tz":-120,"elapsed":15003,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import StratifiedShuffleSplit\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import urllib.request\n","import os, tarfile\n","import imageio\n","from scipy.io import loadmat\n","# from tensorflow.examples.tutorials.mnist import input_data\n","%matplotlib inline\n","\n","import tensorflow as tf\n","print(tf.test.gpu_device_name())\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"tEDytSfzts_2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["SVHN_URL_TRAIN = 'https://www.dropbox.com/s/k02n8imqlqx3wk1/train_32x32.mat?dl=1'\n","SVHN_URL_TEST = 'https://www.dropbox.com/s/et2dulb99ld6fez/test_32x32.mat?dl=1'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L0yQDzlctpcl","colab_type":"text"},"cell_type":"markdown","source":["# Utility functions"]},{"metadata":{"id":"8hVxGP31tpcr","colab_type":"text"},"cell_type":"markdown","source":["#### ToDos\n","- Create a function to fetch data from a url.\n","- Check if it is already downloaded.\n","- Check if the file is csv or tar gz etc.\n","- Add cross-validation code to be able to use sklearn cross_val_score function to quickly evaluate the performance."]},{"metadata":{"id":"9GsUFbnYLXXr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def fetch_data(URL, DOWNLOAD_FOLDER, DOWNLOAD_FILE):\n","  if not os.path.isdir(DOWNLOAD_FOLDER):\n","   os.makedirs(DOWNLOAD_FOLDER)\n","  \n","  if not os.path.isfile(DOWNLOAD_FOLDER+DOWNLOAD_FILE):\n","    print('Beginning file download...')\n","    urllib.request.urlretrieve(URL, DOWNLOAD_FOLDER+DOWNLOAD_FILE)\n","    print('Done.')\n","  \n","  svhn_data = loadmat(DOWNLOAD_FOLDER+DOWNLOAD_FILE)\n","  \n","  return svhn_data\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"LDR5Fhkttpcv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def split_train_test(XY, n_splits=1, test_size=0.2, random_state=42):\n","    split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n","    for train_index, test_index in split.split(XY[0], XY[1]):\n","        X_train, Y_train = XY[0][train_index,:], XY[1][train_index]\n","        X_test, Y_test = XY[0][test_index,:], XY[1][test_index]\n","        \n","    return X_train, Y_train, X_test, Y_test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"httI2oVntpdD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def get_svhn_data(url, download_folder, download_file, split_data=False):\n","  \n","  \n","  svhn_dict = fetch_data(url, download_folder, download_file)\n","  \n","  \n","  X = svhn_dict['X']\n","  Y = svhn_dict['y']\n","  Y_new = np.zeros(Y.shape, dtype=np.float32)\n","  labels = np.arange(0,10,1)\n","  for i in labels[1:]:\n","    locs = np.where(Y==i)[0]\n","    Y_new[locs,:] = Y[locs,:]\n","    \n","  #locs = np.where(Y_train==10)[0]\n","  #Y_new[locs,:] = Y[locs,:]\n","  \n","  \n","  \n","  #X = (X - X.mean(axis=1, keepdims=True)) / X.std(axis=1, keepdims=True)\n","  sz = X.shape\n","  X_new = np.zeros((sz[3], sz[2], sz[0], sz[1]), dtype=np.float32)\n","  for i in range(sz[3]):\n","    for j in range(sz[2]):\n","      X_new[i,j,:,:] = X[:,:,j,i]                   # <---- FOR PYTORCH (N x Channels x Width x Height)\n","    \n","  if split_data:\n","      return split_train_test((X_new, Y), n_splits=1, test_size=0.2, random_state=42)\n","\n","  return X_new, Y_new"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kO2DdjKqfCar","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"d2f0f30b-d4d7-4af6-e5dc-346bf09e097a","executionInfo":{"status":"ok","timestamp":1526405547522,"user_tz":-120,"elapsed":923,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["labels = np.arange(0,10,1)\n","print(labels[1:])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[1 2 3 4 5 6 7 8 9]\n"],"name":"stdout"}]},{"metadata":{"id":"8VA8Ab7PtpdW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def one_hot_encoder(label):\n","    encoder = OneHotEncoder(dtype=np.float32)\n","    label_1hot = encoder.fit_transform(label.reshape(-1,1))\n","    print('The labels are: {}'.format(np.unique(label)))\n","    return label_1hot"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7r_M9DL7WzsY","colab_type":"text"},"cell_type":"markdown","source":["# Load data"]},{"metadata":{"id":"RVTY55DhtpcV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["root_folder = 'drive/app/svhn/'\n","# root_folder = 'D:/dev/data/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"07JKossstpdi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":109},"outputId":"2f6b1789-ac4e-4abb-e226-85dff58ae86a","executionInfo":{"status":"ok","timestamp":1526405571907,"user_tz":-120,"elapsed":20194,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["X_train, Y_train = get_svhn_data(SVHN_URL_TRAIN, root_folder, 'train_32x32.mat', \n","                                 split_data=False)\n","\n","X_test, Y_test = get_svhn_data(SVHN_URL_TEST, root_folder, 'test_32x32.mat', \n","                               split_data=False)\n","\n","# X_train, Y_train = get_svhn_data(svhn_dict=svhn_data, split_data=True)\n","print(\"Train: [{}, {}], Test: [{}, {}]\".format(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape))\n","# print(\"Train: [{}, {}]\".format(X_train.shape, Y_train.shape))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Beginning file download...\n","Done.\n","Beginning file download...\n","Done.\n","Train: [(73257, 3, 32, 32), (73257, 1)], Test: [(26032, 3, 32, 32), (26032, 1)]\n"],"name":"stdout"}]},{"metadata":{"id":"nCMfq3D_HtvV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":72},"collapsed":true,"outputId":"ac844f6f-2611-4818-e9b2-7eb35fe78134","executionInfo":{"status":"ok","timestamp":1526405573667,"user_tz":-120,"elapsed":1690,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["!ls -l drive/app/svhn"],"execution_count":13,"outputs":[{"output_type":"stream","text":["total 240548\r\n","-rw-r--r-- 1 root root  64275384 May 15 17:32 test_32x32.mat\r\n","-rw-r--r-- 1 root root 182040794 May 15 17:32 train_32x32.mat\r\n"],"name":"stdout"}]},{"metadata":{"id":"tDmUQitEgKyn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# #f, ax = plt.subplots(10,1,figsize=(150, 5))\n","\n","# i=10\n","# #for i in range(10):\n","# idx = np.where(Y_train==i)[0][0]\n","# #print(idx)\n","# img = np.zeros([32,32,3])\n","# img[:,:,0] = X_train[idx,0,:,:]\n","# img[:,:,1] = X_train[idx,1,:,:]\n","# img[:,:,1] = X_train[idx,2,:,:]\n","# plt.imshow(img)\n","# plt.title(Y_train[idx,:])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0I4IA-eHtpd0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"eb46f069-0318-4694-989d-d2b179186d76","executionInfo":{"status":"ok","timestamp":1526405575359,"user_tz":-120,"elapsed":669,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["Y_train_1hot = one_hot_encoder(Y_train).toarray().view(np.float32)\n","Y_test_1hot = one_hot_encoder(Y_test).toarray().view(np.float32)\n","# print(Y_train_1hot[0:2])\n","# print(type(Y_train_1hot))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["The labels are: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n","The labels are: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"],"name":"stdout"}]},{"metadata":{"id":"KCFxdqUmK0Ix","colab_type":"text"},"cell_type":"markdown","source":["# IGNORE"]},{"metadata":{"id":"2OlfKOzvtpd4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def init_weights(in_features, out_features):\n","    W = np.random.randn(in_features, out_features) / sqrt(in_features)\n","    b = np.zeros(out_features)\n","    return W, b"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yvWmqYMitpeA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class HiddenLinearLayer(object):\n","    def __init__(self, in_features, out_features, activation_fn):\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.activation_fn = activation_fn\n","        \n","        W, b = init_weights(in_features, out_features)\n","        \n","        self.W = tf.Variable(W.astype(np.float32))\n","        self.b = tf.Variable(b.astype(np.float32))\n","        \n","        \n","    def forward(self, x):\n","        return self.activation_fn(tf.matmul(x, self.W) + self.b)\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"oK8HO0XGtpeG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def weight_variable(shape):\n","  initial = tf.truncated_normal(shape, stddev=0.1)\n","  return tf.Variable(initial)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VD_ZIbQ_tpeL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def bias_variable(shape):\n","  initial = tf.constant(0.1, shape=shape)\n","  return tf.Variable(initial)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y0pfrVIrtpeS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def conv2d(x, W):\n","  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9n8vMJ_otpeY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def max_pool_2x2(x):\n","  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n","                        strides=[1, 2, 2, 1], padding='SAME')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"flFb78F1LBa2","colab_type":"text"},"cell_type":"markdown","source":["# Model definition"]},{"metadata":{"id":"9zj7hpiBtpeh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class CNN(nn.Module):\n","  \n","  def __init__(self, width, height, n_channels):\n","    super(CNN, self).__init__()\n","    \n","    self.conv_1 = nn.Conv2d(in_channels=n_channels, out_channels=32, kernel_size=5, stride=1, padding=2)\n","    self.conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n","    self.conv_3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=2)\n","    self.conv_4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, stride=1, padding=2)\n","    self.fc5 = nn.Linear(in_features=256*8*8, out_features=1024)\n","    self.fc6 = nn.Linear(in_features=1024, out_features=10)\n","    self.activation = nn.ReLU()\n","    self.maxpool = nn.MaxPool2d(kernel_size=2)\n","    \n","    \n","  def forward(self, X):\n","    \n","    out = self.conv_1(X)\n","    out = self.activation(out)\n","    out = self.conv_2(out)\n","    out = self.activation(out)\n","    #print(out.size())\n","    out = self.maxpool(out)\n","    #print(out.size())\n","    out = self.conv_3(out)\n","    out = self.activation(out)\n","    out = self.conv_4(out)\n","    out = self.activation(out)\n","    #print(out.size())\n","    out = self.maxpool(out)\n","    #print(out.size())\n","    out = out.view(out.size(0), -1)\n","    out = self.fc5(out)\n","    out = self.activation(out)\n","    out = self.fc6(out)\n","    \n","    return out\n","  \n","  \n","  def fit(self, X, Y, criterion, optimizer, epochs, n_batches, batch_size, print_time):\n","    \n","    X = torch.from_numpy(X).double()\n","    Y = torch.from_numpy(Y).long()\n","    \n","    train_data = torch.utils.data.TensorDataset(X, Y)\n","    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","    \n","    iteration = 0\n","    for epoch in range(epochs):\n","      for i, (x, y) in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","          x = Variable(x.cuda())\n","          y = Variable(y.cuda())\n","        else:\n","          x = Variable(x)\n","          y = Variable(y)\n","\n","        optimizer.zero_grad()\n","        outputs = self.forward(x)\n","        loss = criterion(outputs, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        iteration += 1\n","\n","        if iteration%print_time == 0:\n","            print('Epoch: {}, Iteration: {}, Loss: {}'.format(epoch, iteration, loss))\n","            #accuracy = predict(test_loader)\n","    \n","#     for epoch in range(epoches):\n","#       X_shuffled, Y_shuffled = shuffle(X, Y)\n","#       for ibatch in range(n_batches):\n","#         X_batch = torch.from_numpy(X_shuffled[ibatch*batch_size:(ibatch+1)*batch_size,:]).double()\n","#         Y_batch = torch.from_numpy(Y_shuffled[ibatch*batch_size:(ibatch+1)*batch_size,:]).double()\n","#         print(type(Y_batch))\n","        \n","#         if torch.cuda.is_available():\n","#           X_batch = Variable(X_batch.cuda()).float()\n","#           Y_batch = Variable(Y_batch.cuda()).type(torch.cuda.LongTensor)\n","#         else:\n","#           X_batch = Variable(X_batch).float()\n","#           Y_batch = Variable(Y_batch).type(torch.LongTensor)\n","          \n","#         optimizer.zero_grad()\n","#         outputs = self.forward(X_batch)\n","#         loss = cost_fn(outputs, Y_batch)\n","#         loss.backward()\n","#         optimizer.step()\n","        \n","#         if ibatch % print_time==0:\n","#           print('Epoch\\Batch: {}\\{}, Train loss: {}'.format(epoch, ibatch, loss))\n","          \n","          \n","  def predict(self, X, n_batches, batch_size):\n","    \n","    correct = 0\n","    test_cost = 0\n","    total = 0\n","    if ibatch%PRINT_TIME == 0:\n","      for ibatch_test in range(n_batches):\n","        X_batch = torch.from_numpy(X_test[ibatch_test*batch_size:(ibatch_test+1)*batch_size,:])\n","        \n","        outputs = self.forward(X_batch)\n","        if first == True:\n","          predicted = torch.argmax(outputs, dim=1)\n","          first = False\n","        else:\n","          predicted = torch.cat((predicted, torch.argmax(outputs, dim=1)))\n","\n","    return predicted\n","  \n","  def score(self, Y, predicted):\n","    \n","    #predicted = torch.argmax(predicted, axis=1)\n","    accuracy = 100*np.mean(Y == predicted.data.numpy())\n","    return accuracy\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"zS9Psa0Ctpes","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["WIDTH = 32\n","HEIGHT = 32\n","N_CHANNELS = 3\n","N_CLASSES = 10\n","BATCH_SIZE =32\n","MAX_ITER = 3\n","N_BATCHES = X_train.shape[0]//BATCH_SIZE\n","PRINT_TIME = N_BATCHES//N_BATCHES\n","TEST_N_BATCHES = X_test.shape[0]//BATCH_SIZE"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FxNsa9Xitpfa","colab_type":"raw"},"cell_type":"markdown","source":["W_conv1 = weight_variable([5, 5, 1, 32])\n","b_conv1 = bias_variable([32])\n","x_image = tf.reshape(x, [-1,28,28,1])\n","h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n","h_pool1 = max_pool_2x2(h_conv1)\n","\n","W_conv2 = weight_variable([5, 5, 32, 64])\n","b_conv2 = bias_variable([64])\n","\n","h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n","h_pool2 = max_pool_2x2(h_conv2)\n","\n","W_fc1 = weight_variable([7 * 7 * 64, 1024])\n","b_fc1 = bias_variable([1024])\n","\n","h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n","h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n","\n","keep_prob = tf.placeholder(tf.float32)\n","h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n","\n","W_fc2 = weight_variable([1024, 10])\n","b_fc2 = bias_variable([10])\n","\n","y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"]},{"metadata":{"id":"6dYP6pqOtpgN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["ann = CNN(WIDTH, HEIGHT, N_CHANNELS)\n","ann = ann.double()\n","if torch.cuda.is_available():\n","  ann.cuda()\n","cost_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(ann.parameters(), lr=0.001)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xGgBO3sw2bCH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":239},"collapsed":true,"outputId":"ce5d8ff3-968d-43ea-ecaf-c81f5cdb1748","executionInfo":{"status":"ok","timestamp":1526393634619,"user_tz":-120,"elapsed":491,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["for parameter in list(ann.parameters()):\n","    print(parameter.size())"],"execution_count":35,"outputs":[{"output_type":"stream","text":["torch.Size([32, 3, 5, 5])\n","torch.Size([32])\n","torch.Size([64, 32, 5, 5])\n","torch.Size([64])\n","torch.Size([128, 64, 5, 5])\n","torch.Size([128])\n","torch.Size([256, 128, 5, 5])\n","torch.Size([256])\n","torch.Size([1024, 16384])\n","torch.Size([1024])\n","torch.Size([10, 1024])\n","torch.Size([10])\n"],"name":"stdout"}]},{"metadata":{"id":"HkZGTnFl2tnx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"collapsed":true,"outputId":"92d30a3d-653d-490b-bef6-96075ed4b5d3","executionInfo":{"status":"ok","timestamp":1526405619177,"user_tz":-120,"elapsed":1632,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["_, _, X_Select, Y_Select = split_train_test((X_train, Y_train), n_splits=1, test_size=0.4, random_state=42)\n","print(X_Select.shape, Y_Select.shape)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(29303, 3, 32, 32) (29303, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"1r23nqfhGg5x","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":562},"outputId":"32451069-98ee-46ae-995f-dbed570d907f","executionInfo":{"status":"error","timestamp":1526405634142,"user_tz":-120,"elapsed":2081,"user":{"displayName":"Anant Vemuri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100979246453766324139"}}},"cell_type":"code","source":["ann.fit(X_train, np.squeeze(Y_train), cost_fn, optimizer, 10, N_BATCHES, BATCH_SIZE, PRINT_TIME)"],"execution_count":21,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-55a2e44cd79c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_BATCHES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRINT_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-ce2824873c82>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, criterion, optimizer, epochs, n_batches, batch_size, print_time)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58"]}]},{"metadata":{"id":"9yGvGqCrp_Dq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!kill -9 -1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D8c1NOGH6mMn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}