{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon forest analysis from satellite images.\n",
    "\n",
    "\n",
    "Data obtained from the kaggle competition https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize whats happening in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:10.342009Z",
     "start_time": "2019-09-19T12:04:10.337074Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:10.508611Z",
     "start_time": "2019-09-19T12:04:10.506446Z"
    }
   },
   "outputs": [],
   "source": [
    "# base_path = '/media/anant/data/amazon_from_space/'\n",
    "base_path = '/media/avemuri/DEV/Data/amazon_from_space/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:10.743484Z",
     "start_time": "2019-09-19T12:04:10.688163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(base_path+'train_v2.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the frequency of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:11.120490Z",
     "start_time": "2019-09-19T12:04:11.082413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 17 unique labels including {'habitation', 'primary', 'bare_ground', 'artisinal_mine', 'selective_logging', 'partly_cloudy', 'conventional_mine', 'clear', 'blooming', 'agriculture', 'blow_down', 'slash_burn', 'water', 'cloudy', 'cultivation', 'road', 'haze'}\n"
     ]
    }
   ],
   "source": [
    "# Print all unique tags\n",
    "from itertools import chain\n",
    "labels_list = list(chain.from_iterable([tags.split(\" \") for tags in train_df['tags'].values]))\n",
    "labels_set = set(labels_list)\n",
    "print(\"There is {} unique labels including {}\".format(len(labels_set), labels_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:11.757891Z",
     "start_time": "2019-09-19T12:04:11.356096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fec080133c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/QAAAHVCAYAAABfSrDYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xm4XVV9//H3BxIIQ5gRcYAoIMgY5KKgzEWrVgUERUQFpaRoLWp/VG1RiihWlMKjUrHBQlAckEkQFFFmUIYESMIktICPFaogMzLz/f1x94Xj9d6bm+QmJ/vc9+t5eLLPWmuv9d2Hvz5n7b1vqgpJkiRJktQuS3W7AEmSJEmSNP8M9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayEAvSZIkSVILGeglSZIkSWohA70kSZIkSS1koJckSZIkqYUmdLsAzb811lijpkyZ0u0yJEmSJEljbNasWfdV1ZqjGWugb6EpU6Ywc+bMbpchSZIkSRpjSX4z2rEG+hZ65t77uff4U7pdhiRJkiS1xpoffl+3SxhzPkMvSZIkSVILGeglSZIkSWohA70kSZIkSS1koJckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQj0KSI5Ls2u06JEmSJEka4N+hn4ckS1fVYYtg3gCpqufGem5JkiRJUu8b1zv0SaYkuTXJyUnmJDk9yfJJ7kpyWJIrgHclmZFkr+acu5J8McmvksxM8pokP0vyP0kOasasmOTCJNclmZtkt471bknyDeA64LNJju2o58Akx3Thq5AkSZIktcy4DvSNDYHpVbU58DDwkab9iararqp+MMQ5v62qbYHLgRnAXsA2wBED5wJ7VNVrgJ2Bf2925AfW+3ZVbQkcDbwjycSm74PASWN6dZIkSZKknuQt9/3h/Mrm+BTg4Ob41BHOOaf5dy6wYlU9AjyS5IkkqwCPAV9MsgPwHPBSYK3mnN9U1VUAVfVYkouAtyW5BZhYVXOHWjDJNGAawMtWW31BrlOSJEmS1EMM9FDDfH5shHOebP59ruN44PMEYF9gTWCrqno6yV3ApGHm/RbwL8CtjLA7X1XTgekAU9d95eCaJUmSJEnjjLfcwzpJtm2O9wGuGIM5Vwb+0IT5nYF1hxtYVVcDLwfeC3x/DNaWJEmSJI0DBnq4BdgvyRxgNeD4MZjzu0Bfkpn079bfOo/xPwSurKoHxmBtSZIkSdI44C338FxVHTSobUrnh6rav+N4SsfxDPpfivcXfcC2DG3TIdq2A44dol2SJEmSpCG5Q99FSVZJchvweFVd2O16JEmSJEntMa536KvqLobeMV9c6z8IvKpb60uSJEmS2ssdekmSJEmSWshAL0mSJElSCxnoJUmSJElqoXH9DH1bTVhzNdb88Pu6XYYkSZIkqYvcoZckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQr4Ur4Wevvd33PONQ7tdhiRJkrpk7Y8c2e0SJC0B3KGXJEmSJKmFDPSSJEmSJLWQgV6SJEmSpBYy0EuSJEmS1EIGekmSJEmSWshAL0mSJElSCxnox0iSw5Mc0u06JEmSJEnjg4F+CZNkQrdrkCRJkiQt+Qz0CyjJB5LMSTI7yXcG9a2X5Pwks5JcnmSjpv3tSa5Ocn2SXyRZq2k/PMn0JBcA3+7C5UiSJEmSWsbd4AWQZBPgUOANVXVfktWAgzuGTAcOqqrbk7wO+AawC3AFsE1VVZK/BT4J/L/mnK2A7arq8WHWnAZMA3jpaistisuSJEmSJLWIgX7B7AKcXlX3AVTV/UkASLIi8HrgtIE2YNnm35cBpyZZG1gGuLNjznOGC/PNGtPp/6GALdZdu8buUiRJkiRJbWSgXzABhgvVSwEPVtXUIfq+DhxTVeck2Qk4vKPvsTGtUJIkSZLU03yGfsFcCLw7yeoAzS33AFTVw8CdSd7V9CXJFk33ysDvmuP9FmO9kiRJkqQeY6BfAFV1E3AkcGmS2cAxg4bsCxzQ9N0E7Na0H07/rfiXA/ctpnIlSZIkST3IW+4XUFWdDJw8TN+dwJuHaD8bOHuI9sPHuj5JkiRJUm9zh16SJEmSpBYy0EuSJEmS1EIGekmSJEmSWshAL0mSJElSCxnoJUmSJElqId9y30IT13wpa3/kyG6XIUmSJEnqInfoJUmSJElqIQO9JEmSJEktZKCXJEmSJKmFDPSSJEmSJLWQL8VroT/d+99c/823d7sMST1my4N+3O0SJEmSNB/coZckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayEAvSZIkSVILjetAn+QdST69gOfOSLJXc/zxJMuPbXWSJEmSJA1v3Ab6JBOq6pyq+tIYTPdxYL4CfZIJY7CuJEmSJGmcan2gT/KjJLOS3JRkWtN2QJLbklyS5IQkxzXtM5Ick+Ri4Kgk+3f0rZXkrCSzm/9en2RKkhs71jokyeGD1j8YeAlwcTMvSR7t6N8ryYxh1l8hyYlJrk1yfZLdFuV3JUmSJEnqHb2wS/yhqro/yXLAtUnOAz4LvAZ4BLgImN0x/lXArlX1bJL9O9q/BlxaVXskWRpYEVh1XotX1deS/COwc1XdN4p6O9f/InBRVX0oySrANUl+UVWPDT6p+bFiGsCLV1tuFMtIkiRJknpZ63fogYOTzAauAl4OvJ/+YH5/VT0NnDZo/GlV9ewQ8+wCHA9QVc9W1UOLqN7O9d8EfDrJDcAlwCRgnaFOqqrpVdVXVX2rrrjMIipNkiRJktQWrd6hT7ITsCuwbVX9KcklwK+BV49w2l/sfo/gGf78R49JozyvRjinc/0Ae1bVr+ejJkmSJEmSWr9DvzLwQBPmNwK2of/ldDsmWbV58dyeo5zrQuDDAEmWTrIS8HvgRUlWT7Is8LZhzn0EmNzx+fdJXp1kKWCPEdb8GfAPSdKsu+Uoa5UkSZIkjXNtD/TnAxOSzAE+T/9t978DvghcDfwCuBkYze3zHwN2TjIXmAVs0tyyf0Qz17nArcOcOx346cBL8YBPN+MvAu4ZYc3PAxOBOc3L9z4/ijolSZIkSSJVNe9RLZNkxap6tNmhPws4sarO6nZdY2XjdVep7/7z9t0uQ1KP2fKgH3e7BEmSpHEvyayq6hvN2Lbv0A/n8OZFczcCdwI/6nI9kiRJkiSNqVa/FG84VXVIt2uQJEmSJGlR6tUdekmSJEmSepqBXpIkSZKkFurJW+573fJrru/LqyRJkiRpnHOHXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayEAvSZIkSVIL+VK8Fnrovtv5yX+9tdtlSGPurQf8pNslSJIkSa3hDr0kSZIkSS1koJckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayEC/BEmyU5Jzu12HJEmSJGnJZ6AfQ+nndypJkiRJWuQMnwspyZQktyT5BnAd8P4kc5PcmOSojnHHJ5mZ5KYkn+tof3OSW5NcAbyzC5cgSZIkSWohA/3Y2BD4NvA3wOeBXYCpwNZJdm/GHFpVfcDmwI5JNk8yCTgBeDuwPfDi4RZIMq35QWDmQ488tQgvRZIkSZLUBgb6sfGbqroK2Bq4pKrurapngO8COzRj3p3kOuB6YBNgY2Aj4M6qur2qCjhluAWqanpV9VVV38qTl1mkFyNJkiRJWvJN6HYBPeKx5t8M1ZnkFcAhwNZV9UCSGcCkprsWfXmSJEmSpF7jDv3Yupr+2+nXSLI0sA9wKbAS/aH/oSRrAW9pxt8KvCLJes3nfRZ3wZIkSZKkdnKHfgxV1T1J/hm4mP7d+p9U1dkASa4HbgLuAK5sxj+RZBpwXpL7gCuATbtSvCRJkiSpVQz0C6mq7qIjhFfV94DvDTFu/2HOP5/+Z+klSZIkSRo1b7mXJEmSJKmFDPSSJEmSJLWQgV6SJEmSpBYy0EuSJEmS1EIGekmSJEmSWsi33LfQymtswFsP+Em3y5AkSZIkdZE79JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayJfitdB9f7yNE09+U7fLkIb0of0u6HYJkiRJ0rjgDr0kSZIkSS1koJckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayEC/iCX5eJLlu12HJEmSJKm3GOgXvY8D8xXokyy9iGqRJEmSJPUIA/0oJflkkoOb42OTXNQc/1WSU5Icn2RmkpuSfK7pOxh4CXBxkoubtjcl+VWS65KclmTFpv2uJIcluQJ4V1cuUpIkSZLUGgb60bsM2L457gNWTDIR2A64HDi0qvqAzYEdk2xeVV8D7gZ2rqqdk6wBfAbYtapeA8wE/rFjjSeqaruq+sHgxZNMa34wmPnoI08vsouUJEmSJLWDgX70ZgFbJZkMPAn8iv5gvz39gf7dSa4Drgc2ATYeYo5tmvYrk9wA7Aes29F/6nCLV9X0quqrqr4VJ08ci+uRJEmSJLXYhG4X0BZV9XSSu4APAr8E5gA7A+sBjwOHAFtX1QNJZgCThpgmwM+rap9hlnlsrOuWJEmSJPUmd+jnz2X0B/fL6N+VPwi4AViJ/jD+UJK1gLd0nPMIMLk5vgp4Q5L1AZIsn+RVi6l2SZIkSVIPMdDPn8uBtYFfVdXvgSeAy6tqNv232t8EnAhc2XHOdOCnSS6uqnuB/YHvJ5lDf8DfaDHWL0mSJEnqEd5yPx+q6kJgYsfnV3Uc7z/MOV8Hvt7x+SJg6yHGTRnDUiVJkiRJPc4dekmSJEmSWshAL0mSJElSCxnoJUmSJElqIQO9JEmSJEkt5EvxWmiN1V/Fh/a7oNtlSJIkSZK6yB16SZIkSZJayEAvSZIkSVILGeglSZIkSWohA70kSZIkSS3kS/Fa6J4HbucLp/51t8uQAPjM3j/rdgmSJEnSuOQOvSRJkiRJLWSglyRJkiSphQz0kiRJkiS1kIFekiRJkqQWMtBLkiRJktRCBnpJkiRJklrIQC9JkiRJUgv1VKBPsnuSjTs+z0iy1xjNvX+S48ZorjGrS5IkSZI0PvVMoE8yAdgd2HheYyVJkiRJarslKtAnmZLk1iQnJ5mT5PQkyyc5LMm1SW5MMj1JmvGXJPlikkuBTwHvAL6S5IYk63XM+1dJzur4/MYkZ45Qx5uTXJdkdpILh+hfN8mFTY0XJlmnaf+znfckjzb/JslxSW5Och7wogWpS5IkSZKkAUtUoG9sCEyvqs2Bh4GPAMdV1dZVtSmwHPC2jvGrVNWOVXUkcA7wT1U1tar+p2PMRcCrk6zZfP4gcNJQizdjTgD2rKotgHcNMew44NtNjd8FvjaPa9qjua7NgAOB1y9AXdOSzEwy87GHn5rHcpIkSZKkXrckBvrfVtWVzfEpwHbAzkmuTjIX2AXYpGP8qfOasKoK+A7wviSrANsCPx1m+DbAZVV1Z3Pu/UOM2Rb4XnP8nabGkewAfL+qnq2qu+kP8vNVV1VNr6q+qupbYaVl5rGcJEmSJKnXTeh2AUOoIT5/A+irqt8mORyY1NH/2CjnPQn4MfAEcFpVPTPMuAxRw7wMjH+G5keS5rGAZYYYs6B1SZIkSZL0vCVxh36dJNs2x/sAVzTH9yVZERjp7fCPAJOH6mh2xu8GPgPMGGGOXwE7JnkFQJLVhhjzS+A9zfG+HTXeBWzVHO8GTGyOLwPek2TpJGsDOy9AXZIkSZIkPW9J3KG/BdgvyX8CtwPHA6sCc+kPzNeOcO4PgBOSHMzQwf+7wJpVdfNwE1TVvUmmAWcmWQr4A/DGQcMOBk5M8k/AvfQ/+w79z96fneQa4EJeuHvgLPofFZgL3AZcOr91SZIkSZLUKf2PcS8ZkkwBzm1efrco5j8OuL6q/mtRzL+g5reul663cn34i9ss4qqk0fnM3j/rdgmSJElSz0gyq6r6RjN2SdyhXySSzKJ/x/z/dbuWTktqXZIkSZKkJdsSFeir6i5gkezOV9VWg9uSXA0sO6j5/VU1d1HUMJSh6pIkSZIkaV6WqEC/uFXV67pdgyRJkiRJC2JJfMu9JEmSJEmah3G9Q99Wa6+6gS8ikyRJkqRxzh16SZIkSZJayEAvSZIkSVILGeglSZIkSWohA70kSZIkSS3kS/Fa6PYH7+AtZ+/T7TI0hJ/u9v1ulyBJkiRpnHCHXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayEAvSZIkSVILGeglSZIkSWohA70kSZIkSS007gJ9kilJbmyOpyZ5a0ffO5J8egHn3T3Jxh2fj0iy68JXLEmSJEnSXxp3gX6QqcDzgb6qzqmqLy3gXLsDzwf6qjqsqn6xkPVJkiRJkjSkngn0ST6QZE6S2Um+k2RGkr06+h8dNH4Z4Ahg7yQ3JNk7yf5JjkuycpK7kizVjF0+yW+TTExyYJJrm3XOaPpeD7wD+Eoz13qd6yf5qyTXJ5mb5MQkyzbtdyX5XJLrmr6NFtf3JUmSJElqt54I9Ek2AQ4FdqmqLYCPzeucqnoKOAw4taqmVtWpHX0PAbOBHZumtwM/q6qngTOrautmnVuAA6rql8A5wD81c/1PR22TgBnA3lW1GTAB+HBHKfdV1WuA44FDRrjGaUlmJpn51MNPzuvyJEmSJEk9ricCPbALcHpV3QdQVfePwZynAns3x+9pPgNsmuTyJHOBfYFN5jHPhsCdVXVb8/lkYIeO/jObf2cBU4abpKqmV1VfVfUts9Kyo78KSZIkSVJP6pVAH6AGtT1Dc31JAiwzn3OeA7wlyWrAVsBFTfsM4KPNbvvngEmjqG0kA9vtz9K/ey9JkiRJ0jz1SqC/EHh3ktUBmhB+F/1BHGA3YOIQ5z0CTB5qwqp6FLgG+CpwblU923RNBu5JMpH+Hfp5zXUrMCXJ+s3n9wOXju6yJEmSJEkaWk8E+qq6CTgSuDTJbOAY4ARgxyTXAK8DHhvi1IuBjQdeijdE/6nA+3jhdnuAzwJXAz+nP6wP+AHwT83L79brqO0J4IPAac1t+s8B31ywK5UkSZIkqV+qBt+priXdyuuvVq//97/udhkawk93+363S5AkSZLUYklmVVXfaMb2xA69JEmSJEnjjYFekiRJkqQWMtBLkiRJktRCBnpJkiRJklrIv3veQhus8kpfviZJkiRJ45w79JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayEAvSZIkSVIL+Zb7Frr9wf/jrWcd1e0yesJP9vhUt0uQJEmSpAXiDr0kSZIkSS1koJckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJaqOcCfZIpSW6cj/Ezkuw1RHtfkq81xzslef0o5vqzcUkOSvKB0dYiSZIkSdJo+Xfoh1FVM4GZzcedgEeBX87jtD8bV1XfXETlSZIkSZLGuZ7boW8sneSEJDcluSDJckkOTHJtktlJzkiyfMf4XZNcnuS2JG+D53fbz00yBTgI+ESSG5Jsn+TtSa5Ocn2SXyRZa5hxhyc5pJlvapKrksxJclaSVZv2S5IcleSaZv3tF+P3JEmSJElqqV4N9BsA/1FVmwAPAnsCZ1bV1lW1BXALcEDH+CnAjsDfAN9MMmmgo6ruAr4JHFtVU6vqcuAKYJuq2hL4AfDJYcZ1+jbwqaraHJgL/GtH34Sqei3w8UHtz0syLcnMJDOfevix+f9GJEmSJEk9pVdvub+zqm5ojmfRH9g3TfIFYBVgReBnHeN/WFXPAbcnuQPYaB7zvww4NcnawDLAnSMNTrIysEpVXdo0nQyc1jHkzEG1/oWqmg5MB1h5/ZfVPOqTJEmSJPW4Xt2hf7Lj+Fn6f7iYAXy0qjYDPgdM6hgzOCDPKzB/HTiumevvBs21IAbqHahVkiRJkqQR9WqgH8pk4J4kE4F9B/W9K8lSSdYDXgn8elD/I835A1YGftcc7zfCOACq6iHggY7n498PXDp4nCRJkiRJozWeAv1ngauBnwO3Dur7Nf0B+6fAQVX1xKD+HwN7DLzsDjgcOC3J5cB9I4zrtB/wlSRzgKnAEWNwTZIkSZKkcSpVPo7dNiuv/7J6w1f+odtl9ISf7PGpbpcgSZIkSc9LMquq+kYzdjzt0EuSJEmS1DMM9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQv7N8xbaYJUX+zI3SZIkSRrn3KGXJEmSJKmFDPSSJEmSJLWQgV6SJEmSpBYy0EuSJEmS1EK+FK+F/vuB+3jbGf/V7TIWq3P3PKDbJUiSJEnSEsUdekmSJEmSWshAL0mSJElSCxnoJUmSJElqIQO9JEmSJEktZKCXJEmSJKmFDPSSJEmSJLWQgX4hJJmS5MZu1yFJkiRJGn8M9JIkSZIktZCBfuEtneSEJDcluSDJckkOTHJtktlJzkiyPECSGzr+ezzJjklWSHJiM/76JLt1+4IkSZIkSUs+A/3C2wD4j6raBHgQ2BM4s6q2rqotgFuAAwCqampVTQU+C8wEfgkcClxUVVsDOwNfSbLC4EWSTEsyM8nMpx5+ZLFcmCRJkiRpyWWgX3h3VtUNzfEsYAqwaZLLk8wF9gU2GRicZAPgK8DeVfU08Cbg00luAC4BJgHrDF6kqqZXVV9V9S2z0uRFeT2SJEmSpBaY0O0CesCTHcfPAssBM4Ddq2p2kv2BnQCanfcfAgdW1d3NOQH2rKpfL66CJUmSJEnt5w79ojEZuCfJRPp36AecBJxUVZd3tP0M+IckAUiy5eIrU5IkSZLUVgb6ReOzwNXAz4FbAZKsC+wFfKjjxXh9wOeBicCc5k/gfb5LNUuSJEmSWsRb7hdCVd0FbNrx+eiO7uOHOGW4H1D+bgzLkiRJkiSNA+7QS5IkSZLUQgZ6SZIkSZJayEAvSZIkSVILGeglSZIkSWohA70kSZIkSS3kW+5baP1V1+DcPQ/odhmSJEmSpC5yh16SJEmSpBYy0EuSJEmS1EIGekmSJEmSWshAL0mSJElSC/lSvBb67wce4O2nn9HtMhbIj/fas9slSJIkSVJPcIdekiRJkqQWMtBLkiRJktRCBnpJkiRJklrIQC9JkiRJUgsZ6CVJkiRJaiEDvSRJkiRJLWSgH6Ukhyc5ZIzmuiRJ31jMJUmSJEkanwz0kiRJkiS1kIF+GEk+kGROktlJvjOob2qSq5r+s5Ks2rQ/v/OeZI0kdzXHyyX5QTP+VGC5pv2AJMd2zHtgkmMW1zVKkiRJktrLQD+EJJsAhwK7VNUWwMcGDfk28Kmq2hyYC/zrPKb8MPCnZvyRwFZN+w+AdySZ2Hz+IHDSMDVNSzIzycynHn54vq9JkiRJktRbDPRD2wU4varuA6iq+wc6kqwMrFJVlzZNJwM7zGO+HYBTmrnmAHOa48eAi4C3JdkImFhVc4eaoKqmV1VfVfUts9JKC35lkiRJkqSeMKHbBSyhAtQCnPcML/xIMmlQ33DzfQv4F+BWhtmdlyRJkiRpMHfoh3Yh8O4kqwMkWW2go6oeAh5Isn3T9H5gYLf+Ll64nX6vjvkuA/Zt5toU2LxjvquBlwPvBb4/1hciSZIkSepN7tAPoapuSnIkcGmSZ4Hr6Q/rA/YDvplkeeAO+p99Bzga+GGS99N/K/2A44GTkswBbgCuGbTkD4GpVfXAmF+MJEmSJKknGeiHUVUn0/98/FB9NwDbDNF+Kx2778BnmvbHgfeMsNx2wLEj9EuSJEmS9Ge85b6LkqyS5Dbg8aq6sNv1SJIkSZLawx36LqqqB4FXdbsOSZIkSVL7uEMvSZIkSVILGeglSZIkSWohb7lvofVXXZUf77Vnt8uQJEmSJHWRO/SSJEmSJLWQgV6SJEmSpBYy0EuSJEmS1EIGekmSJEmSWsiX4rXQ/zzwCHuccfGYzHXWnjuPyTySJEmSpMXLHXpJkiRJklrIQC9JkiRJUgsZ6CVJkiRJaiEDvSRJkiRJLWSglyRJkiSphQz0kiRJkiS1kIFekiRJkqQWWqIDfZIpSW7sdh2LS5IZSfbqdh2SJEmSpCXfEh3oF0aSCYtgziTp2e9MkiRJktQebQinE5KcnGROktOTLJ/ksCTXJrkxyfQkAUhySZIvJrkU+FiSNZOc0Yy9NskbhlukGfvzJNcl+c8kv0myRnOXwC1JvgFcB7w8yT5J5jbrH9Uxx6Mdx3slmdEcz0jytSS/THLHwC588wPBcUluTnIe8KJF8g1KkiRJknpOGwL9hsD0qtoceBj4CHBcVW1dVZsCywFv6xi/SlXtWFX/DnwVOLaqtgb2BL41wjr/ClxUVa8BzgLWGVTDt6tqS+Bp4ChgF2AqsHWS3UdxHWsD2zW1fqlp26OZezPgQOD1w52cZFqSmUlmPvnwQ6NYTpIkSZLUy9oQ6H9bVVc2x6fQH4p3TnJ1krn0B+tNOsaf2nG8K3BckhuAc4CVkkweZp3tgB8AVNX5wAMdfb+pqqua462BS6rq3qp6BvgusMMoruNHVfVcVd0MrNW07QB8v6qeraq7gYuGO7mqpldVX1X1LbvSyqNYTpIkSZLUy8b8OfNFoIb4/A2gr6p+m+RwYFJH/2Mdx0sB21bV46NYJyP0dc450rjOWicN6ntymDkGX58kSZIkSfPUhh36dZJs2xzvA1zRHN+XZEVgpLfCXwB8dOBDkqkjjL0CeHcz7k3AqsOMuxrYsXm+fummpkubvt8neXXz4rw9RlhrwGXAe5IsnWRtYOdRnCNJkiRJUisC/S3AfknmAKsBxwMnAHOBHwHXjnDuwUBf80K9m4GDRhj7OeBNSa4D3gLcAzwyeFBV3QP8M3AxMBu4rqrObro/DZxL/63z94zi2s4Cbm+u5Xhe+GFAkiRJkqQRpco7vgGSLAs8W1XPNHcEHF9VI+3od82q621YO335m2My11l7elOAJEmSJC0pksyqqr7RjG3DM/SLyzrAD5vb5Z+i/63zkiRJkiQtkcZdoE/yQeBjg5qvrKq/B7bsQkmSJEmSJM23cRfoq+ok4KRu1yFJkiRJ0sJow0vxJEmSJEnSIONuh74XrLfqZF9mJ0mSJEnjnDv0kiRJkiS1kIFekiRJkqQWMtBLkiRJktRCBnpJkiRJklrIl+Jn9e72AAAb4ElEQVS10B0PPMHeZ9w2ZN+pe75qMVcjSZIkSeoGd+glSZIkSWohA70kSZIkSS1koJckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJaaLEF+iQzkuy1AOdNSfLejs99Sb42hnXtn+S4sZqvY95vJdl4rOeVJEmSJAlgQrcLGIUpwHuB7wFU1UxgZjcLGo2q+ttu1yBJkiRJ6l0LtUOfZIUk5yWZneTGJHsn2SrJpUlmJflZkrWHOG/IMUnWT/KLZr7rkqwHfAnYPskNST6RZKck5yZZKsldSVbpmPe/k6yVZM0kZyS5tvnvDaO8nnWTXJhkTvPvOk37ekmuauY6IsmjTftSSb6R5Kampp8M3IWQ5JIkfc3xo0mObK7rqiRrjTTvMLVNSzIzycwnH35gtP+LJEmSJEk9amFvuX8zcHdVbVFVmwLnA18H9qqqrYATgSM7T0gycYQx3wX+o6q2AF4P3AN8Gri8qqZW1bED81TVc8DZwB7NvK8D7qqq3wNfBY6tqq2BPYFvjfJ6jgO+XVWbN7UM3Nr/VeCrzXx3d4x/J/13EGwG/C2w7TDzrgBc1VzXZcCB85j3L1TV9Krqq6q+ZVdadZSXI0mSJEnqVQt7y/1c4OgkRwHnAg8AmwI/TwKwNP2hvNOGQ41JMhl4aVWdBVBVTwA0Y4ZzKnAYcBLwnuYzwK7Axh3nrpRkclU9Mo/r2Zb+kA7wHeDLHe27N8ffA45ujrcDTmt+XPi/JBcPM+9T9H8/ALOAN85jXkmSJEmSRrRQgb6qbkuyFfBW4N+AnwM3VdVwO9UAGWpMkpUWoIRfAesnWZP+YPyFpn0pYNuqenwB5uxU8+gf8deGDk9X1cBcz9KOdxdIkiRJkpZgC/sM/UuAP1XVKfTvLr8OWDPJtk3/xCSbDDrt10ONqaqHgf9NsnvTvmyS5YFHgMlDrd+E5LOAY4BbquqPTdcFwEc76pw6ykv6Jf07/QD7Alc0x1fRf+s+Hf00/Xs2z9KvBew0ynUGDDevJEmSJEkjWthn6DcDrklyA3Ao/be/7wUclWQ2cAP9z8I/r6qeGmHM+4GDk8yhP1y/GJgDPNO8UO4TQ9RwKvA+XrjdHuBgoK95ud3NwEGjvJ6DgQ82678f+FjT/nHgH5NcA6wNPNS0nwH8L3Aj8J/A1R19ozHcvJIkSZIkjSgv3Amu4TR3CjxeVZXkPcA+VbVb07diVT2aZHXgGuANVfV/CzvvSFZbb9N645fPHLLv1D1fNcqrkiRJkiQtaZLMqqq+0Yz1We7R2Qo4Lv1v2XsQ+FBH37nNn85bBvj8aMP8KOaVJEmSJGlY4ybQJ/kgL9xCP+DKqvr7eZ1bVZcDWwzTt9OC1jTSvJIkSZIkjWTcBPqqOon+P28nSZIkSVLrjZtA30teueokn5WXJEmSpHFuYd9yL0mSJEmSusBAL0mSJElSCxnoJUmSJElqIQO9JEmSJEkt5EvxWujeB59h+pl/GLJv2jtftJirkSRJkiR1gzv0kiRJkiS1kIFekiRJkqQWMtBLkiRJktRCBnpJkiRJklrIQC9JkiRJUgsZ6CVJkiRJaiEDvSRJkiRJLdSaQJ/k40mW7/j8kySrjDD+W0k2XsC19k9y3IKcO2ieEWuUJEmSJGlBtSLQJ1ka+DjwfKCvqrdW1YPDnVNVf1tVNy+O+kaoYcQaJUmSJElaUEtEoE/yoySzktyUZFrT9miSI5JcDRwKvAS4OMnFTf9dSdZIskKS85LMTnJjkr2b/kuS9HXMdWQz5qokazXtb09ydZLrk/xioH0U9c5IcnySi5PckWTHJCcmuSXJjI5xAzVOafpOaK7xgiTLNWPWS3J+c/2XJ9lo7L5ZSZIkSVKvWiICPfChqtoK6AMOTrI6sAJwY1W9rqqOAO4Gdq6qnQed+2bg7qraoqo2Bc4fYv4VgKuqagvgMuDApv0KYJuq2hL4AfDJ+ah5VWAX4BPAj4FjgU2AzZJMHWL8BsB/VNUmwIPAnk37dOAfmus/BPjGUIslmZZkZpKZjz70x/koU5IkSZLUiyZ0u4DGwUn2aI5fTn/4fRY4YxTnzgWOTnIUcG5VXT7EmKeAc5vjWcAbm+OXAacmWRtYBrhzPmr+cVVVkrnA76tqLkCSm4ApwA2Dxt9ZVQNts4ApSVYEXg+clmRg3LJDLVZV0+kP/6y7/tSajzolSZIkST2o6zv0SXYCdgW2bXbQrwcmAU9U1bPzOr+qbgO2oj/Y/1uSw4YY9nRVDYTgZ3nhh4yvA8dV1WbA3zXrjtaTzb/PdRwPfB7qh5LOMQM1LAU8WFVTO/579XzUIEmSJEkap7oe6IGVgQeq6k/N8+PbDDPuEWDy4MYkLwH+VFWnAEcDr5nPtX/XHO83H+eNiap6GLgzybsA0m+LxV2HJEmSJKl9loRAfz4wIckc4PPAVcOMmw78dOCleB02A65JcgP9L8/7wnysfTj9t7tfDtw3X1WPnX2BA5LMBm4CdutSHZIkSZKkFskLd6KrLdZdf2od+uULhuyb9s4XLeZqJEmSJEljJcmsquobzdglYYdekiRJkiTNpyXlLfdLpCSHAu8a1HxaVR3ZjXokSZIkSRpgoB9BE9wN75IkSZKkJY633EuSJEmS1ELu0LfQmqtM8OV3kiRJkjTOuUMvSZIkSVILGeglSZIkSWohA70kSZIkSS1koJckSZIkqYV8KV4LPXL/M1z03XuH7Ntl3zUXczWSJEmSpG5wh16SJEmSpBYy0EuSJEmS1EIGekmSJEmSWshAL0mSJElSCxnoJUmSJElqIQO9JEmSJEkt1POBPsmUJDcO0X5Jkr5FuG5fkq8tqvklSZIkSeObf4d+EamqmcDMbtchSZIkSepNPb9D35iQ5OQkc5KcnmT5zs4k+ySZm+TGJEeNov3RJEclmZXkF0le2+z435HkHc2YnZKc2xwfnuTEjjEHd8z12SS3Jvl5ku8nOWTRfx2SJEmSpLYbL4F+Q2B6VW0OPAx8ZKAjyUuAo4BdgKnA1kl2H669OW0F4JKq2gp4BPgC8EZgD+CIYWrYCPhr4LXAvyaZ2NzyvyewJfBOYNhHAJJMSzIzycwHH/7jgnwHkiRJkqQeMl4C/W+r6srm+BRgu46+rekP5/dW1TPAd4EdRmgHeAo4vzmeC1xaVU83x1OGqeG8qnqyqu4D/gCs1dRxdlU9XlWPAD8e7gKqanpV9VVV3yorrT5fFy9JkiRJ6j3jJdDXCJ8zzDnDtQM8XVUDczwHPAlQVc8x/HsJnuw4frYZN9IakiRJkiQNa7wE+nWSbNsc7wNc0dF3NbBjkjWSLN30XzpC+1i6Anh7kklJVgT+ZoznlyRJkiT1qPES6G8B9ksyB1gNOH6go6ruAf4ZuBiYDVxXVWcP1z6WRVXVtcA5zfxn0v9W/IfGcg1JkiRJUm/KC3eOqxuSrFhVjzZv3r8MmFZV1410zoavnFrHf/7nQ/btsu+ai6BKSZIkSdLikGRWVQ37wvRO/h367pueZGNgEnDyvMK8JEmSJElgoO+6qnpvt2uQJEmSJLXPeHmGXpIkSZKknmKglyRJkiSphbzlvoUmrzbBl99JkiRJ0jjnDr0kSZIkSS1koJckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQS5IkSZLUQr7lvoWe/MPT3H7c75//vMFH1+piNZIkSZKkbnCHXpIkSZKkFjLQS5IkSZLUQgZ6SZIkSZJayEAvSZIkSVILGeglSZIkSWohA70kSZIkSS1koJckSZIkqYV6MtAnuSRJ3wKcNyPJXqMcu1OSc+e/OkmSJEmSFl5PBvo2SDKh2zVIkiRJktqr9YE+yQpJzksyO8mNSfYe1H98kplJbkryuY72LyW5OcmcJEd3nLJDkl8muWMUu/UrJTmrmeebSZZq5n60Y529ksxojmckOSbJxcBRSQ5PcmJzR8EdSQ4e4TqnNdcx8/5H7x/9FyRJkiRJ6km9sEv8ZuDuqvobgCQrAx/u6D+0qu5PsjRwYZLNgf8F9gA2qqpKskrH+LWB7YCNgHOA00dY+7XAxsBvgPOBd85jPMCrgF2r6tkkhzfr7AxMBn6d5PiqenrwSVU1HZgOsNk6W9Q81pAkSZIk9bjW79ADc4FdkxyVZPuqemhQ/7uTXAdcD2xCfwB/GHgC+FaSdwJ/6hj/o6p6rqpuBtaax9rXVNUdVfUs8H36fwiYl9Oa8QPOq6onq+o+4A+jWFOSJEmSpPYH+qq6DdiK/mD/b0kOG+hL8grgEOCvqmpz4DxgUlU9Q//u+hnA7vTvrg94suM481p+mM+d7ZMGjXls0OfO9Z6lN+6akCRJkiQtYq0P9EleAvypqk4BjgZe09G9Ev0B+qEkawFvac5ZEVi5qn4CfByYuoDLvzbJK5pn5/cGrmjaf5/k1U37Hgs4tyRJkiRJw+qF3eDNgK8keQ54mv7n548GqKrZSa4HbgLuAK5szpkMnJ1kEv278J9YwLV/BXypqeEy4Kym/dPAucBvgRuBFRdwfkmSJEmShpQq36/WNputs0Wd+ckLnv+8wUd97F6SJEmSekGSWVXVN5qxrb/lXpIkSZKk8agXbrlfpJJsBnxnUPOTVfW6btQjSZIkSRIY6Oepquay4C/NkyRJkiRpkTDQt9CyL5roc/OSJEmSNM75DL0kSZIkSS1koJckSZIkqYUM9JIkSZIktZCBXpIkSZKkFjLQt9DTv3+c/zvmpm6XIUmSJEnqIgO9JEmSJEktZKCXJEmSJKmFDPSSJEmSJLWQgV6SJEmSpBYy0EuSJEmS1EIGekmSJEmSWshAL0mSJElSC7U60CeZkuTGIdovSdK3iNfeKcm5i3INSZIkSZKG0+pAL0mSJEnSeNULgX5CkpOTzElyepLlOzuT7JNkbpIbkxzVtL07yTHN8ceS3NEcr5fkiuEWSvLmJLc2Y97Z0b5akh81NVyVZPOmfW6SVdLvj0k+0LR/J8muSfZPcmaS85PcnuTLI6w9LcnMJDP/+NgDC/F1SZIkSZJ6QS8E+g2B6VW1OfAw8JGBjiQvAY4CdgGmAlsn2R24DNi+GbY98MckLwW2Ay4fapEkk4ATgLc357y4o/tzwPVNDf8CfLtpvxJ4A7AJcEfHmtsAVzXHU4G9gc2AvZO8fKj1q2p6VfVVVd/qK6w6r+9E/7+9e4+1rDzrOP79ZbiUlpE7iJTL0KAVkHKZURAYCxigxASwE8WQQLEppmJbbGgKIRpMJKk1WqXFEqp0CsVCpSAklgxkuEyVOpTbAFMYGC4NyFigCAVjQeDxj/Ue2HPc58wZODP7rDPfT/Jmr/2u27v2c951zrPXu9aRJEmSpFluNiT0T1XVv7Xpb9Il5WMWALdV1XNV9TpwJbCwqv4T2DrJXGB34B+BhXQJ99CEHvgg8ERVPVpV1fY15gjgCoCqugXYIck2bVsLW/kq8Cvti4MXquqVtu7Sqnqpqn4G/BDY8x1/EpIkSZKkTcZsSOhrkveZZL3vA2cAq+gS7yOBw+iuqk91X5Ptp3h7JMCRwG3Ac8Ai1v7S4NWB6TeAzSbZvyRJkiRJwOxI6PdIclib/j1g8B745cBvJNkxyZw2//Y2bxlwTnu9FzgKeLWqXppgPw8D85J8YGBfY5YBp0L39Hvg+ar6aVU9BewI7FNVj7e2ncPEowAkSZIkSZqS2ZDQPwScnuR+YHu6oe0AVNUa4DzgVmAFcE9VXd9mf49uuP2yqnoDeIq1vwxYSxsSfybwL+2heD8amH0BML+14QvA6QPzlgOPDOxzt8n2I0mSJEnSVKS7HVx98qHd96slf/xtfv6z+426KZIkSZKkaZTk7qqaP5VlZ8MVekmSJEmSNjk+gG2IJNcB88ZVf76qloyiPZIkSZIkjWdCP0RVnTzqNkiSJEmSNBmH3EuSJEmS1EMm9D20+S5b+UA8SZIkSdrEmdBLkiRJktRDJvSSJEmSJPWQCb0kSZIkST1kQi9JkiRJUg+Z0PfQ68++zLNfXjrqZkiSJEmSRsiEXpIkSZKkHjKhlyRJkiSph0zoJUmSJEnqIRN6SZIkSZJ6yIRekiRJkqQeMqGXJEmSJKmHTOglSZIkSeqh3iX0Sc5O8t6B999Nsu007+OCJOdMw3bumI72SJIkSZI0Xu8SeuBs4K2EvqpOqKoXR9ieCVXVr4+6DZIkSZKk2WlKCX2S05Lcn2RFkiuS7JlkaatbmmSPttziJBcluSPJ40kWtfqrk5wwsL3FST6aZE6Sv0zyg7atP2jzP5zktiTXJHk4yZXpfBr4BeDWJLe2ZZ9MsmOb/mySB1s5u9XtleShJF9LsjLJTUm2avM+0fa9Isl3Bq/8r+PzuC3Jl5Isa9tekOTaJI8m+fOB5V6Z7HjavEOS3J7k7iRLkuw6wT7PTHJXkrt+8sqM/P5CkiRJkrQRrTOhT7IfcD5wdFV9CPgM8BXg8qo6ALgSuGhglV2BI4DfAr7Q6q4CfrdtbwvgGOC7wMeBl6pqAbAA+ESSeW2dg+iuxu8L7A0cXlUXAc8AR1XVUePaeQhwBvBrwKFtWwe12fsAF1fVfsCLwEdb/bVVtaAd10OtPVP1WlUtBC4BrgfOAvYHPpZkhyHL/7/jSbI58GVgUVUdAlwGXDhsZ1V1aVXNr6r5O2w9rXcYSJIkSZJ6aLMpLHM0cE1VPQ9QVS8kOQz47Tb/CuCLA8v/c1W9CfwwyS6t7kbgoiRbAscDy6rqf5IcCxwwdiUf2IYu+X4NuLOqngZIch+wF/Cvk7TzCOC6qvrvts61wJHADcATVXVfW+7uti2A/dsV9W2BrYElU/g8xtzQXh8AVlbVmrbfx4HdgZ+MW37Y8bxI9yXAze2C/RxgzXq0QZIkSZK0iZpKQh+g1rHM4PxXx61LVf0syW3AcXRX6r81MP9TVbVWIp3kw+O288YU2ppJ5o3f1lZtejFwUlWtSPIx4MPr2Mewbb45bvtvMrytw44ndF8GHLYe+5UkSZIkaUr30C8FfmdsGHmS7YE7gFPa/FOZ/Mr5mKvohsQfydtXwpcAn2xDz0nyi0net47tvAzMHVK/DDgpyXvbNk4GvreObc0F1rT9nzqFY5huq4Cd2ogHkmzebnGQJEmSJGlS67xCX1Urk1wI3J7kDeBe4NPAZUk+BzxHl6ivy03A5cANVfVaq/t7uqHn97SHxD0HnLSO7VwK3JhkzeB99FV1T5LFwJ1j266qe5PsNcm2/gRYDvyIbuj8sC8KNpiqeq3dbnBRkm3o4vE3wMqN2Q5JkiRJUv+kal2j6TXTHLjHL9VNn/s7dv7UMaNuiiRJkiRpGiW5u6rmT2XZPv4fekmSJEmSNnlTeSjeJivJxcDh46r/tqq+Por2SJIkSZI0xoR+ElV11qjbIEmSJEnSMA6576HNdp7r/fOSJEmStIkzoZckSZIkqYdM6CVJkiRJ6iH/bV0PJXkZWDXqduhd2RF4ftSN0LtiDGcH49h/xrD/jOHsYBz7zxjOHHtW1U5TWdCH4vXTqqn+X0LNTEnuMob9ZgxnB+PYf8aw/4zh7GAc+88Y9pND7iVJkiRJ6iETekmSJEmSesiEvp8uHXUD9K4Zw/4zhrODcew/Y9h/xnB2MI79Zwx7yIfiSZIkSZLUQ16hlyRJkiSph0zoJUmSJEnqIRP6HklyfJJVSVYnOXfU7dHakjyZ5IEk9yW5q9Vtn+TmJI+21+1afZJc1GJ5f5KDB7Zzelv+0SSnj+p4NhVJLkvybJIHB+qmLW5JDmk/F6vbutm4Rzj7TRDDC5L8R+uP9yU5YWDeeS0eq5IcN1A/9BybZF6S5S22VyfZYuMd3aYhye5Jbk3yUJKVST7T6u2LPTFJDO2LPZLkPUnuTLKixfHPWv3Qzz7Jlu396jZ/r4FtrVd8NT0mieHiJE8M9MUDW73n076rKksPCjAHeAzYG9gCWAHsO+p2WdaK0ZPAjuPqvgic26bPBf6iTZ8A3AgEOBRY3uq3Bx5vr9u16e1GfWyzuQALgYOBBzdE3IA7gcPaOjcCHxn1Mc+2MkEMLwDOGbLsvu38uSUwr51X50x2jgW+DZzSpi8BPjnqY55tBdgVOLhNzwUeabGyL/akTBJD+2KPSusfW7fpzYHlrY8N/eyBPwQuadOnAFe/0/haNngMFwOLhizv+bTnxSv0/fGrwOqqeryqXgOuAk4ccZu0bicC32jT3wBOGqi/vDr/DmybZFfgOODmqnqhqv4LuBk4fmM3elNSVcuAF8ZVT0vc2ryfq6rvV/cb8PKBbWmaTBDDiZwIXFVVr1bVE8BquvPr0HNsu+pwNHBNW3/w50HTpKrWVNU9bfpl4CFgN+yLvTFJDCdiX5yBWp96pb3dvJVi4s9+sI9eAxzTYrVe8d3Ah7VJmSSGE/F82nMm9P2xG/DUwPunmfwXpTa+Am5KcneSM1vdLlW1Bro/doCdW/1E8TTOM8N0xW23Nj2+XhvHH7Xhg5eNDdVm/WO4A/BiVb0+rl4bSBuyexDdVSX7Yg+NiyHYF3slyZwk9wHP0iVxjzHxZ/9WvNr8l+hi5d85IzQ+hlU11hcvbH3xS0m2bHWeT3vOhL4/ht2b4v8cnFkOr6qDgY8AZyVZOMmyE8XTOM9s6xs34zk6XwU+ABwIrAH+qtUbwxksydbAd4Czq+qnky06pM44zgBDYmhf7JmqeqOqDgTeT3dF/ZeHLdZejeMMND6GSfYHzgM+CCygG0b/+ba4Mew5E/r+eBrYfeD9+4FnRtQWDVFVz7TXZ4Hr6H4J/rgNTaK9PtsWnyiexnlmmK64Pd2mx9drA6uqH7c/aN4EvkbXH2H9Y/g83fDDzcbVa5ol2ZwuEbyyqq5t1fbFHhkWQ/tif1XVi8BtdPdVT/TZvxWvNn8bulug/DtnBhiI4fHttpiqqleBr/PO+6Ln0xnGhL4/fgDs054yugXdg0duGHGb1CR5X5K5Y9PAscCDdDEaeyro6cD1bfoG4LT2ZNFDgZfacNIlwLFJtmvDEo9tddq4piVubd7LSQ5t9xSeNrAtbUBjSWBzMl1/hC6Gp7QnM88D9qF7uM/Qc2y7P/BWYFFbf/DnQdOk9Y9/AB6qqr8emGVf7ImJYmhf7JckOyXZtk1vBfwm3fMQJvrsB/voIuCWFqv1iu+GP7JNxwQxfHjgy9HQ3fM+2Bc9n/bZup6aZ5k5he4plI/Q3ct0/qjbY1krNnvTPal1BbByLD5095EtBR5tr9u3+gAXt1g+AMwf2Nbv0z08ZjVwxqiPbbYX4Ft0w0D/l+5b549PZ9yA+XS/NB8DvgJk1Mc828oEMbyixeh+uj9Wdh1Y/vwWj1UMPJl3onNs6993ttj+E7DlqI95thXgCLohm/cD97Vygn2xP2WSGNoXe1SAA4B7W7weBP50ss8eeE97v7rN3/udxteywWN4S+uLDwLf5O0n4Xs+7XlJC4okSZIkSeoRh9xLkiRJktRDJvSSJEmSJPWQCb0kSZIkST1kQi9JkiRJUg+Z0EuSJEmS1EMm9JIkSZIk9ZAJvSRJkiRJPfR/Vg3JToWDTCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_s = pd.Series(labels_list).value_counts() # To sort them by count\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.barplot(x=labels_s, y=labels_s.index, orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:13.059428Z",
     "start_time": "2019-09-19T12:04:12.469838Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, fbeta_score\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "\n",
    "from ignite.engine import create_supervised_trainer, create_supervised_evaluator, Events\n",
    "from ignite.metrics import Accuracy, Precision, Recall, Loss, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get data as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:02:16.314768Z",
     "start_time": "2019-09-19T10:02:16.306925Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data(base_path=base_path, folder_name='train-jpg', csv_file='train_v2.csv'):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    df_train = pd.read_csv(base_path+csv_file)\n",
    "\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "    label_map = {l: i for i, l in enumerate(labels)}\n",
    "    inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "    for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "        img = cv2.imread(base_path+folder_name+'/'+'{}.jpg'.format(f))\n",
    "        targets = np.zeros(17)\n",
    "        for t in tags.split(' '):\n",
    "            targets[label_map[t]] = 1 \n",
    "        X.append(cv2.resize(img, (32, 32)))\n",
    "        #y.append(targets)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(df_train['tags'].str.split()).astype(np.float32)\n",
    "    \n",
    "    # y = np.array(y, np.uint8)\n",
    "    X = np.array(X, np.float16) / 255.\n",
    "                         \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:02:57.787448Z",
     "start_time": "2019-09-19T10:02:16.316322Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:39<00:00, 1028.22it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:02:57.793844Z",
     "start_time": "2019-09-19T10:02:57.790566Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 3, 32, 32) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "X = np.moveaxis(X, (0,1,2,3), (0,2,3,1))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:02:57.922568Z",
     "start_time": "2019-09-19T10:02:57.796927Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32384, 3, 32, 32) (32384, 17) (8095, 3, 32, 32) (8095, 17)\n"
     ]
    }
   ],
   "source": [
    "SPLIT = 0.2\n",
    "dataset_size = X.shape[0]\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(SPLIT * dataset_size))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "x_train, y_train = X[train_indices], y[train_indices]\n",
    "x_valid, y_valid = X[val_indices], y[val_indices]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:02:58.067271Z",
     "start_time": "2019-09-19T10:02:57.924118Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(y_train).float())\n",
    "valid_dataset = TensorDataset(torch.from_numpy(x_valid).float(), torch.from_numpy(y_valid).float())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
    "                          shuffle=True, num_workers=8, \n",
    "                          pin_memory=True)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, \n",
    "                          shuffle=True, num_workers=8, \n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:03:05.386401Z",
     "start_time": "2019-09-19T10:02:58.069063Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256, 17])\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    x, y = next(iter(train_loader))\n",
    "    print(x.shape, y.shape)\n",
    "    x, y = next(iter(valid_loader))\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from pytorch dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:17.199444Z",
     "start_time": "2019-09-19T12:04:17.160396Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(base_path+'train_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:17.743874Z",
     "start_time": "2019-09-19T12:04:17.729747Z"
    }
   },
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, base_folder, csv_file, folder_name, select_indices=None, transform=None):\n",
    "        self.csv_file = csv_file\n",
    "        self.labels_df = pd.read_csv(base_path+csv_file)\n",
    "        self.base_folder = base_folder\n",
    "        self.image_list = [f for f in glob.glob(base_path+folder_name+'/*.jpg')]\n",
    "        self.transform = transform\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.labels = self.mlb.fit_transform(self.labels_df['tags'].str.split()).astype(np.float32)\n",
    "        \n",
    "        if select_indices is not None:\n",
    "            self.labels_df = self.labels_df.loc[select_indices]\n",
    "            self.image_list = list(np.array(self.image_list)[select_indices])\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_list[index])\n",
    "        image = image.convert('RGB')\n",
    "        # image = cv2.imread(self.image_list[index])\n",
    "        \n",
    "        label = torch.from_numpy(self.labels[index])\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:23.863439Z",
     "start_time": "2019-09-19T12:04:23.858755Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE = True\n",
    "SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:24.527970Z",
     "start_time": "2019-09-19T12:04:24.522126Z"
    }
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "train_transform_augmented = transforms.Compose([transforms.Resize(IMG_SIZE),\n",
    "                                                #transforms.ColorJitter(brightness=0.5),\n",
    "                                                transforms.RandomVerticalFlip(),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                normalize])\n",
    "valid_transform_augmented = transforms.Compose([transforms.Resize(IMG_SIZE),\n",
    "                                                transforms.ToTensor(), \n",
    "                                                normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:25.700052Z",
     "start_time": "2019-09-19T12:04:24.970041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32384 8095 32384 8095\n"
     ]
    }
   ],
   "source": [
    "image_list = [f for f in glob.glob(base_path+'train-jpg'+'/*.jpg')]\n",
    "SPLIT = 0.2\n",
    "dataset_size = len(image_list)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(SPLIT * dataset_size))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_dataset = AmazonDataset(base_path, 'train_v2.csv', 'train-jpg', \n",
    "                              select_indices=train_indices,\n",
    "                              transform=train_transform_augmented)\n",
    "valid_dataset = AmazonDataset(base_path, 'train_v2.csv', 'train-jpg', \n",
    "                              select_indices=val_indices,\n",
    "                              transform=valid_transform_augmented)\n",
    "\n",
    "print(len(train_indices), len(val_indices), len(train_dataset), len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:26.207686Z",
     "start_time": "2019-09-19T12:04:26.203151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 127\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=SHUFFLE)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=SHUFFLE)\n",
    "print(len(train_loader), len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:30.863454Z",
     "start_time": "2019-09-19T12:04:27.809157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64, 17])\n",
      "torch.Size([64, 3, 224, 224]) torch.Size([64, 17])\n",
      "torch.Size([64, 3, 224, 224]) torch.Size([64, 17])\n",
      "torch.Size([64, 3, 224, 224]) torch.Size([64, 17])\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    x, y = next(iter(train_loader))\n",
    "    print(x.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:40:46.061680Z",
     "start_time": "2019-09-19T10:40:46.046322Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNet, self).__init__()\n",
    "        \n",
    "        self.conv11 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv12 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.conv13 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        \n",
    "        self.conv21 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv22 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.conv23 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        \n",
    "        self.conv2_drop_1 = nn.Dropout2d(0.25)\n",
    "        self.conv2_drop_2 = nn.Dropout2d(0.25)\n",
    "        self.linear_drop = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(576, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 17)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = self.conv2_drop_1(F.max_pool2d(F.relu(self.conv13(x)), (2,2)))\n",
    "        \n",
    "        x = F.relu(self.conv21(x))\n",
    "        x = F.relu(self.conv22(x))\n",
    "        x = self.conv2_drop_2(F.max_pool2d(F.relu(self.conv23(x)), (2,2)))\n",
    "                \n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "                        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.linear_drop(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:40:47.145143Z",
     "start_time": "2019-09-19T10:40:47.121590Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 32, 32])\n",
      "torch.Size([3, 17])\n"
     ]
    }
   ],
   "source": [
    "img = torch.from_numpy(np.random.randn(3,3,32,32)).float()\n",
    "print(img.shape)\n",
    "model = BaseNet()\n",
    "out = model(img)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:34.133676Z",
     "start_time": "2019-09-19T12:04:34.123240Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdvancedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdvancedNet, self).__init__()\n",
    "        \n",
    "        pretrained_model = models.resnet34(pretrained=True)\n",
    "        self.pretrained_model = nn.Sequential(*list(pretrained_model.children())[0:9])\n",
    "        for parameter in self.pretrained_model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "            \n",
    "        self.additional_stacked_layers = nn.Sequential(nn.Linear(512, 512),\n",
    "                                                       nn.ReLU(inplace=True),\n",
    "                                                       nn.Dropout2d(0.5),\n",
    "                                                       nn.Linear(512, 256),\n",
    "                                                       nn.ReLU(inplace=True),\n",
    "                                                       nn.Linear(256, 128),\n",
    "                                                       nn.ReLU(inplace=True),\n",
    "                                                       nn.Dropout2d(0.5),\n",
    "                                                       nn.Linear(128, 17))\n",
    "        \n",
    "#         self.classifier = nn.Sequential(self.pretrained_model,\n",
    "#                                         self.additional_stacked_layers)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained_model(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = self.additional_stacked_layers(x)\n",
    "        \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:35.607934Z",
     "start_time": "2019-09-19T12:04:34.738964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 224, 224])\n",
      "torch.Size([3, 17])\n"
     ]
    }
   ],
   "source": [
    "img = torch.from_numpy(np.random.randn(3,3,224,224)).float()\n",
    "print(img.shape)\n",
    "model = AdvancedNet()\n",
    "out = model(img)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:38.622418Z",
     "start_time": "2019-09-19T12:04:38.612464Z"
    }
   },
   "outputs": [],
   "source": [
    "class KerasMetrics:\n",
    "\tdef precision(self, y_true, y_pred):\n",
    "\t\ttrue_positives = k.backend.sum(k.backend.round(k.backend.clip(y_true * y_pred, 0, 1)))\n",
    "\t\tpredicted_positives = k.backend.sum(k.backend.round(k.backend.clip(y_pred, 0, 1)))\n",
    "\t\tprecision = true_positives / (predicted_positives + k.backend.epsilon())\n",
    "\t\treturn precision\n",
    "\n",
    "\tdef recall(self, y_true, y_pred):\n",
    "\t\ttrue_positives = k.backend.sum(k.backend.round(k.backend.clip(y_true * y_pred, 0, 1)))\n",
    "\t\tpossible_positives = k.backend.sum(k.backend.round(k.backend.clip(y_true, 0, 1)))\n",
    "\t\trecall = true_positives / (possible_positives + k.backend.epsilon())\n",
    "\t\treturn recall\n",
    "\n",
    "\tdef fbeta_score(self, y_true, y_pred, beta=2):\n",
    "\t\tif beta < 0:\n",
    "\t\t\traise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "\t\tif k.backend.sum(k.backend.round(k.backend.clip(y_true, 0, 1))) == 0:\n",
    "\t\t\treturn 0\n",
    "\n",
    "\t\tp = self.precision(y_true, y_pred)\n",
    "\t\tr = self.recall(y_true, y_pred)\n",
    "\t\tbb = beta ** 2\n",
    "\t\tfbeta_score = (1 + bb) * (p * r) / (bb * p + r + k.backend.epsilon())\n",
    "\t\treturn fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:39.351541Z",
     "start_time": "2019-09-19T12:04:39.341689Z"
    }
   },
   "outputs": [],
   "source": [
    "class FBetaScore(Metric):\n",
    "    \"\"\"\n",
    "    Calculate the fbeta score.\n",
    "\n",
    "    - `update` must receive output of the form `(y_pred, y)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, beta=2, output_transform=lambda x: x):\n",
    "        self.precision = Precision(average=True)\n",
    "        self.recall = Recall(average=True)\n",
    "        \n",
    "        super(FBetaScore, self).__init__(output_transform)\n",
    "        self.beta = beta\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.precision.reset()\n",
    "        self.recall.reset()\n",
    "\n",
    "    def update(self, output):\n",
    "        \n",
    "        self.precision.update(output)\n",
    "        self.recall.update(output)\n",
    "\n",
    "    def compute(self):\n",
    "#         if self._num_examples == 0:\n",
    "#             raise NotComputableError('FBetaScore must have at least one example before it can be computed')\n",
    "        p = self.precision.compute()\n",
    "        r = self.recall.compute()\n",
    "        bb = self.beta ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + 1e-07) \n",
    "        return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:40.029121Z",
     "start_time": "2019-09-19T12:04:40.026557Z"
    }
   },
   "outputs": [],
   "source": [
    "# keras_metrics = KerasMetrics() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train - from data as numpy array and simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:42.859010Z",
     "start_time": "2019-09-19T12:04:42.832007Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:43.711711Z",
     "start_time": "2019-09-19T12:04:43.544718Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-384afbff413d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_supervised_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m evaluator = create_supervised_evaluator(model, device=device, metrics={'accuracy': Accuracy(), \n\u001b[1;32m      5\u001b[0m                                                                        \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseNet' is not defined"
     ]
    }
   ],
   "source": [
    "model = BaseNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "trainer = create_supervised_trainer(model, optimizer, F.binary_cross_entropy, device=device)\n",
    "evaluator = create_supervised_evaluator(model, device=device, metrics={'accuracy': Accuracy(), \n",
    "                                                                       'loss': Loss(F.binary_cross_entropy),\n",
    "                                                                       'recall': Recall(),\n",
    "                                                                       'precision': Precision(),\n",
    "                                                                       'fbeta': FBetaScore()}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:04:44.793242Z",
     "start_time": "2019-09-19T12:04:44.775945Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c9d5a7590d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     print(\"Epoch: {0} Loss: {1}\".format(epoch, loss))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "# def log_training_loss(trainer):\n",
    "#     epoch = trainer.state.epoch\n",
    "#     #iteration = engine.state.iteration\n",
    "#     loss = trainer.state.output\n",
    "#     print(\"Epoch: {0} Loss: {1}\".format(epoch, loss)) \n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    loss = trainer.state.output\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    \n",
    "#     print(\"Training Results - Epoch: {0}  Training loss: {2}\"\n",
    "#           .format(trainer.state.epoch,\n",
    "#                   loss))\n",
    "    print(\"Training Results - Epoch: {}  Training loss: {:.2f} Avg accuracy: {:.2f} Avg loss: {:.2f}  Avg Recall: {:.2f}  Avg Precision: {:.2f}  Avg fbeta: {:.2f}\"\n",
    "          .format(trainer.state.epoch,\n",
    "                  loss,\n",
    "                  metrics['accuracy'], \n",
    "                  metrics['loss'],\n",
    "                  metrics['recall'],\n",
    "                  metrics['precision'],\n",
    "                  metrics['fbeta']))\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_evaluator_on_validation_data(engine):\n",
    "    evaluator.run(valid_loader)\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_trainer_on_training_data(engine):\n",
    "    evaluator.run(train_loader)\n",
    "    #print(\"Epoch: {0} Loss: {1}\".format(epoch, loss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T10:54:37.115247Z",
     "start_time": "2019-09-19T10:47:45.136482Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Training loss: 0.30 Avg accuracy: 0.90 Avg loss: 0.27  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 2  Training loss: 0.27 Avg accuracy: 0.90 Avg loss: 0.25  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 3  Training loss: 0.27 Avg accuracy: 0.90 Avg loss: 0.24  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 4  Training loss: 0.25 Avg accuracy: 0.90 Avg loss: 0.24  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 5  Training loss: 0.25 Avg accuracy: 0.90 Avg loss: 0.24  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 6  Training loss: 0.25 Avg accuracy: 0.90 Avg loss: 0.24  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 7  Training loss: 0.25 Avg accuracy: 0.90 Avg loss: 0.24  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 8  Training loss: 0.24 Avg accuracy: 0.90 Avg loss: 0.24  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 9  Training loss: 0.25 Avg accuracy: 0.91 Avg loss: 0.23  Avg Recall: 0.53  Avg Precision: 0.88  Avg fbeta: 0.57\n",
      "Training Results - Epoch: 10  Training loss: 0.23 Avg accuracy: 0.91 Avg loss: 0.22  Avg Recall: 0.55  Avg Precision: 0.87  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 11  Training loss: 0.21 Avg accuracy: 0.91 Avg loss: 0.21  Avg Recall: 0.60  Avg Precision: 0.84  Avg fbeta: 0.64\n",
      "Training Results - Epoch: 12  Training loss: 0.23 Avg accuracy: 0.92 Avg loss: 0.21  Avg Recall: 0.62  Avg Precision: 0.84  Avg fbeta: 0.65\n",
      "Training Results - Epoch: 13  Training loss: 0.21 Avg accuracy: 0.92 Avg loss: 0.21  Avg Recall: 0.60  Avg Precision: 0.86  Avg fbeta: 0.64\n",
      "Training Results - Epoch: 14  Training loss: 0.24 Avg accuracy: 0.92 Avg loss: 0.21  Avg Recall: 0.62  Avg Precision: 0.84  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 15  Training loss: 0.24 Avg accuracy: 0.92 Avg loss: 0.21  Avg Recall: 0.62  Avg Precision: 0.85  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 16  Training loss: 0.20 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.84  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 17  Training loss: 0.22 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.85  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 18  Training loss: 0.23 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.62  Avg Precision: 0.85  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 19  Training loss: 0.22 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.84  Avg fbeta: 0.67\n",
      "Training Results - Epoch: 20  Training loss: 0.21 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.85  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 21  Training loss: 0.21 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.64  Avg Precision: 0.84  Avg fbeta: 0.67\n",
      "Training Results - Epoch: 22  Training loss: 0.23 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.84  Avg fbeta: 0.67\n",
      "Training Results - Epoch: 23  Training loss: 0.21 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.85  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 24  Training loss: 0.22 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.85  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 25  Training loss: 0.22 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.85  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 26  Training loss: 0.21 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.85  Avg fbeta: 0.67\n",
      "Training Results - Epoch: 27  Training loss: 0.18 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.63  Avg Precision: 0.85  Avg fbeta: 0.66\n",
      "Training Results - Epoch: 28  Training loss: 0.23 Avg accuracy: 0.92 Avg loss: 0.20  Avg Recall: 0.64  Avg Precision: 0.85  Avg fbeta: 0.67\n",
      "Training Results - Epoch: 29  Training loss: 0.21 Avg accuracy: 0.92 Avg loss: 0.19  Avg Recall: 0.63  Avg Precision: 0.86  Avg fbeta: 0.67\n",
      "Training Results - Epoch: 30  Training loss: 0.19 Avg accuracy: 0.92 Avg loss: 0.19  Avg Recall: 0.67  Avg Precision: 0.84  Avg fbeta: 0.70\n",
      "Training Results - Epoch: 31  Training loss: 0.19 Avg accuracy: 0.92 Avg loss: 0.19  Avg Recall: 0.69  Avg Precision: 0.83  Avg fbeta: 0.71\n",
      "Training Results - Epoch: 32  Training loss: 0.21 Avg accuracy: 0.93 Avg loss: 0.19  Avg Recall: 0.67  Avg Precision: 0.86  Avg fbeta: 0.70\n",
      "Training Results - Epoch: 33  Training loss: 0.19 Avg accuracy: 0.93 Avg loss: 0.19  Avg Recall: 0.67  Avg Precision: 0.86  Avg fbeta: 0.70\n",
      "Training Results - Epoch: 34  Training loss: 0.17 Avg accuracy: 0.93 Avg loss: 0.19  Avg Recall: 0.69  Avg Precision: 0.85  Avg fbeta: 0.72\n",
      "Training Results - Epoch: 35  Training loss: 0.20 Avg accuracy: 0.93 Avg loss: 0.18  Avg Recall: 0.68  Avg Precision: 0.85  Avg fbeta: 0.71\n",
      "Training Results - Epoch: 36  Training loss: 0.18 Avg accuracy: 0.93 Avg loss: 0.19  Avg Recall: 0.70  Avg Precision: 0.84  Avg fbeta: 0.72\n",
      "Training Results - Epoch: 37  Training loss: 0.20 Avg accuracy: 0.93 Avg loss: 0.18  Avg Recall: 0.70  Avg Precision: 0.84  Avg fbeta: 0.72\n",
      "Training Results - Epoch: 38  Training loss: 0.17 Avg accuracy: 0.93 Avg loss: 0.18  Avg Recall: 0.69  Avg Precision: 0.85  Avg fbeta: 0.72\n",
      "Training Results - Epoch: 39  Training loss: 0.19 Avg accuracy: 0.93 Avg loss: 0.18  Avg Recall: 0.67  Avg Precision: 0.87  Avg fbeta: 0.71\n",
      "Training Results - Epoch: 40  Training loss: 0.19 Avg accuracy: 0.93 Avg loss: 0.18  Avg Recall: 0.69  Avg Precision: 0.85  Avg fbeta: 0.72\n",
      "Training Results - Epoch: 41  Training loss: 0.20 Avg accuracy: 0.93 Avg loss: 0.18  Avg Recall: 0.70  Avg Precision: 0.85  Avg fbeta: 0.72\n",
      "Training Results - Epoch: 42  Training loss: 0.18 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.69  Avg Precision: 0.86  Avg fbeta: 0.72\n",
      "Training Results - Epoch: 43  Training loss: 0.18 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.70  Avg Precision: 0.86  Avg fbeta: 0.73\n",
      "Training Results - Epoch: 44  Training loss: 0.21 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.70  Avg Precision: 0.86  Avg fbeta: 0.73\n",
      "Training Results - Epoch: 45  Training loss: 0.15 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.71  Avg Precision: 0.86  Avg fbeta: 0.74\n",
      "Training Results - Epoch: 46  Training loss: 0.18 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.71  Avg Precision: 0.86  Avg fbeta: 0.74\n",
      "Training Results - Epoch: 47  Training loss: 0.20 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.70  Avg Precision: 0.88  Avg fbeta: 0.73\n",
      "Training Results - Epoch: 48  Training loss: 0.19 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.71  Avg Precision: 0.86  Avg fbeta: 0.74\n",
      "Training Results - Epoch: 49  Training loss: 0.18 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.70  Avg Precision: 0.88  Avg fbeta: 0.73\n",
      "Training Results - Epoch: 50  Training loss: 0.18 Avg accuracy: 0.93 Avg loss: 0.17  Avg Recall: 0.71  Avg Precision: 0.86  Avg fbeta: 0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x7f78282c6cc0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - using data from pytorch dataloader and advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:05:13.424442Z",
     "start_time": "2019-09-19T12:05:13.420539Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:05:17.768915Z",
     "start_time": "2019-09-19T12:05:14.223471Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AdvancedNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainer = create_supervised_trainer(model, optimizer, F.binary_cross_entropy, device=device)\n",
    "evaluator = create_supervised_evaluator(model, device=device, metrics={'accuracy': Accuracy(), \n",
    "                                                                       'loss': Loss(F.binary_cross_entropy),\n",
    "                                                                       'recall': Recall(),\n",
    "                                                                       'precision': Precision(),\n",
    "                                                                       'fbeta': FBetaScore()}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T12:05:18.401146Z",
     "start_time": "2019-09-19T12:05:18.396104Z"
    }
   },
   "outputs": [],
   "source": [
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "# def log_training_loss(trainer):\n",
    "#     epoch = trainer.state.epoch\n",
    "#     #iteration = engine.state.iteration\n",
    "#     loss = trainer.state.output\n",
    "#     print(\"Epoch: {0} Loss: {1}\".format(epoch, loss)) \n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    loss = trainer.state.output\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    \n",
    "#     print(\"Training Results - Epoch: {0}  Training loss: {2}\"\n",
    "#           .format(trainer.state.epoch,\n",
    "#                   loss))\n",
    "    print(\"Training Results - Epoch: {}  Training loss: {:.2f} Avg accuracy: {:.2f} Avg loss: {:.2f}  Avg Recall: {:.2f}  Avg Precision: {:.2f}  Avg fbeta: {:.2f}\"\n",
    "          .format(trainer.state.epoch,\n",
    "                  loss,\n",
    "                  metrics['accuracy'], \n",
    "                  metrics['loss'],\n",
    "                  metrics['recall'],\n",
    "                  metrics['precision'],\n",
    "                  metrics['fbeta']))\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_evaluator_on_validation_data(engine):\n",
    "    evaluator.run(valid_loader)\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_trainer_on_training_data(engine):\n",
    "    evaluator.run(train_loader)\n",
    "    #print(\"Epoch: {0} Loss: {1}\".format(epoch, loss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-19T12:05:24.456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Training loss: 0.29 Avg accuracy: 0.91 Avg loss: 0.26  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 2  Training loss: 0.28 Avg accuracy: 0.91 Avg loss: 0.26  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n",
      "Training Results - Epoch: 3  Training loss: 0.26 Avg accuracy: 0.91 Avg loss: 0.26  Avg Recall: 0.57  Avg Precision: 0.81  Avg fbeta: 0.60\n"
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
